{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch    as t\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP Reseaux de neurones et Convolution\n",
    "\n",
    "Dans ce TP, vous utilisez le formalisme le plus haut niveau de pyTorch (très proche de Keras), qui masque tous les détails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 0 - fonction de visualisation (a ne pas lire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def visualize_pytorch_classifier(X, y, predict=None,**kwargs):\n",
    "    X_ = X.data.numpy()\n",
    "    y_ = y.data.numpy()\n",
    "    \n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # Plot the training points\n",
    "    ax.scatter(X_[:, 0], X_[:, 1], c=y_, s=30, cmap='rainbow',\n",
    "               clim=(y_.min(), y_.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    #ax.axis('off')\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    if predict:\n",
    "        xx, yy = np.meshgrid(np.linspace(*xlim, num=200),\n",
    "                             np.linspace(*ylim, num=200))\n",
    "        xxyy   = np.c_[xx.ravel(), yy.ravel()]\n",
    "        Z      = np.array([predict(Variable(t.from_numpy(d)).float(),**kwargs).data.numpy()\n",
    "                           for d in xxyy]).reshape(xx.shape)\n",
    "\n",
    "        # Create a color plot with the results\n",
    "        n_classes = len(np.unique(y.data.numpy()))\n",
    "        contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                               levels=np.arange(n_classes + 1) - 0.5,\n",
    "                               cmap='rainbow', #clim=(y_.min(), y_.max()),\n",
    "                               zorder=1)\n",
    "\n",
    "        ax.set(xlim=xlim, ylim=ylim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1 - Régression Logistique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On reprend les memes donnees que dans le TP précédent\n",
    "# On va apprendre une régression logistique dessus\n",
    "n = 400\n",
    "\n",
    "# On crée des donnees non separables lineairement:\n",
    "X = Variable(t.randn(n,2))\n",
    "y = X[:,0]**2-2*X[:,1]>0\n",
    "y = y.float()\n",
    "\n",
    "visualize_pytorch_classifier(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(2, 1),   # Couche lineaire z = w0+w1.x1+x2.x2.   Les parametres wj sont initialises aleatoirement\n",
    "    nn.Sigmoid()       # fonction de transfert sigmoide\n",
    ")\n",
    "\n",
    "fonction_de_cout = t.nn.BCELoss()  # fonction de cout de la regression logistique: y.log(p)+(1-y).log(1-p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction sur l'exemple 0:\n",
    "y_pred = net(X[0])\n",
    "print( y_pred )\n",
    "\n",
    "# cout\n",
    "print( fonction_de_cout( y_pred,y[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tous les parametres sont stockes dans net.parameters\n",
    "print(list( net.parameters() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simple_learn(X,y,net,fonction_de_cout,ntrials=500,learning_rate = 0.05):\n",
    "\n",
    "    for trial in range(ntrials):\n",
    "        i = np.random.randint(0,n)\n",
    "        xi= X[i]\n",
    "\n",
    "        y_pred = net(xi)\n",
    "        cout   = fonction_de_cout(y_pred, y[i])\n",
    "\n",
    "        cout.backward()\n",
    "\n",
    "        for param in net.parameters():\n",
    "            param.data -= learning_rate * param.grad.data\n",
    "\n",
    "        net.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "simple_learn(X,y,net,fonction_de_cout,ntrials=500,learning_rate = 0.05)\n",
    "visualize_pytorch_classifier(X,y,net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 - Réseau de neurones multi-couches\n",
    "\n",
    "Ici, on va recoder avec `nn.Sequential` le réseau de neurones du TP précédent... mais en beaucoup moins de lignes de code !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On crée le meme réseau (a 2 couches cachées) que durant le dernier TP\n",
    "net2 = nn.Sequential(\n",
    "    nn.Linear(2, 3),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(3,1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# et on applique la meme procédure d'apprentissage\n",
    "simple_learn(X,y,net2,fonction_de_cout,ntrials=1000,learning_rate = 0.5)\n",
    "\n",
    "# et on visualise\n",
    "visualize_pytorch_classifier(X,y,net2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q: Affichez les poids des différents neurones\n",
    "#### Q: Construisez un réseau à 3 couches cachées et deux neurones par couche cachée, et entrainez-le de nouveau\n",
    "\n",
    "#### Créez une base de test `X_test` et `y_test` en utilisant la même procédure de création de données que pour `X` et `y`, et mesurez l'erreur de classification comise par ces réseaux sur ce jeu de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
